# Agentic RAG Benchmark

Benchmarking AgenticRAG systems and its viability in the face of long context optimized recursive methods like Recursive RAG and Recursive LMs.

**Target:** ACL/NAACL 2026 publication

## Quick Start

### 1. Setup Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Unix/Mac)
source .venv/bin/activate

# Install dependencies
pip install -e ".[dev]"
```

### 2. Configure API Keys

```bash
# Copy example env file
cp .env.example .env

# Edit .env and add your OpenAI API key
# OPENAI_API_KEY=sk-your-key-here
```

### 3. Validate Pipeline

```bash
python scripts/test_pipeline.py
```

### 4. Run Baseline Experiment

```bash
python scripts/run_experiment.py --config configs/vanilla.yaml
```

## Project Structure

```
agentic_rag_benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Base abstractions
â”‚   â”œâ”€â”€ architectures/  # RAG implementations
â”‚   â”œâ”€â”€ retrieval/      # BM25, Dense, Hybrid
â”‚   â”œâ”€â”€ data/           # Dataset loaders
â”‚   â”œâ”€â”€ evaluation/     # Metrics
â”‚   â””â”€â”€ utils/          # Cache, logging
â”œâ”€â”€ configs/            # YAML configurations
â”œâ”€â”€ prompts/            # Prompt templates
â”œâ”€â”€ scripts/            # Experiment runners
â””â”€â”€ tests/              # Unit tests
```

## Implemented Architectures

| Architecture | Type | Status |
|--------------|------|--------|
| Vanilla RAG | Baseline | âœ… Complete |
| ReAct RAG | Agentic | ðŸ”² Planned |
| Self-RAG | Agentic | ðŸ”² Planned |
| Planner RAG | Agentic | ðŸ”² Planned |
| IRCoT | Recursive | ðŸ”² Planned |
| REAP | Recursive | ðŸ”² Planned |
| Recursive LM | RLM | ðŸ”² Planned |

## Datasets

- **HotpotQA** (implemented) - Multi-hop QA with bridge/comparison questions
- **MuSiQue** (planned) - Multi-hop with explicit decomposition
- **2WikiMultiHopQA** (planned) - Wikipedia-based reasoning

## License

MIT License - see [LICENSE](LICENSE) for details.
